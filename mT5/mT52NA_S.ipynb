{"cells":[{"cell_type":"code","source":["pip install --upgrade pip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b-BAtmYkeCqn","executionInfo":{"status":"ok","timestamp":1685259601991,"user_tz":-480,"elapsed":6397,"user":{"displayName":"許家紳","userId":"14766431505425888321"}},"outputId":"413ca012-1b8e-4a7c-9148-abde627d6e17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7570,"status":"ok","timestamp":1685259609558,"user":{"displayName":"許家紳","userId":"14766431505425888321"},"user_tz":-480},"id":"NxNWTEIyZwGk","outputId":"2d6ac8cb-fbf5-4ccc-81e0-742752ef14e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.19.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n"]}],"source":["pip install transformers datasets accelerate"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H9JmZoeFX0k0","executionInfo":{"status":"ok","timestamp":1685259611991,"user_tz":-480,"elapsed":2454,"user":{"displayName":"許家紳","userId":"14766431505425888321"}},"outputId":"c2f25831-8baa-4df0-e49e-521436a65053"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1685259611991,"user":{"displayName":"許家紳","userId":"14766431505425888321"},"user_tz":-480},"id":"-KWI5nmAZwEC","outputId":"7da47c17-0e1e-4659-9a66-fd698b07d0b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun May 28 07:40:11 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   64C    P8    12W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"UZ_vMDyRmzhV"},"source":["# 抓dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uCqfm7jVmr5r"},"outputs":[],"source":["from datasets import list_datasets, load_dataset\n","from pprint import pprint\n","import json"]},{"cell_type":"code","source":["with open(\"train_social2.json\",'r',encoding='utf-8') as train:\n","    data = json.load(train)\n","    train_sen1 = []\n","    trainlabel = []\n","    for line in data:\n","        train_sen1.append(line[0]+\"</s>\"+line[1])\n","        trainlabel.append(line[2])\n","#pprint(data)\n"],"metadata":{"id":"kHAay5FBMCve"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(\"dev_social2.json\",'r',encoding='utf-8') as dev:\n","    data = json.load(dev)\n","    eval_sen1 = []\n","    eval_sen2 = []\n","    evallabel = []\n","    for line in data:\n","        eval_sen1.append(line[0]+\"</s>\"+line[1])\n","        evallabel.append(line[2])\n","#pprint(data)\n"],"metadata":{"id":"Rgj3kf5DO1Na"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(\"test_social2.json\",'r',encoding='utf-8') as test:\n","    data = json.load(test)\n","    test_sen1 = []\n","    test_sen2 = []\n","    testlabel = []\n","    for line in data:\n","        test_sen1.append(line[0]+\"</s>\"+line[1])\n","        testlabel.append(line[2])\n","#pprint(data)\n"],"metadata":{"id":"CbVFFBJjO2tw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pRV-LNtXm_9M"},"source":["## dataset裡分成三個 train(訓練用) validation(每次訓縣完測試訓練情形用) test(最終算分用)"]},{"cell_type":"markdown","metadata":{"id":"ImHce8r9aOeS"},"source":["## 把每一筆資料集的每一項拆開"]},{"cell_type":"markdown","metadata":{"id":"MJK9LiU9bK8n"},"source":["# 選擇和使用tokenizer，具體要使用哪個tokenizer可以去huggingface官網找"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2002,"status":"ok","timestamp":1685259614728,"user":{"displayName":"許家紳","userId":"14766431505425888321"},"user_tz":-480},"id":"NUurbcxzJYs5","outputId":"5d3438f2-113d-47cd-844c-8466829c39d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import torch\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","source":["pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U3-bJrIiYDmj","executionInfo":{"status":"ok","timestamp":1685259619096,"user_tz":-480,"elapsed":4372,"user":{"displayName":"許家紳","userId":"14766431505425888321"}},"outputId":"dbaf9948-45e1-4a02-ac27-fda1c1ae55a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PpCKvf10IJeR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685259620603,"user_tz":-480,"elapsed":1530,"user":{"displayName":"許家紳","userId":"14766431505425888321"}},"outputId":"73a4ff6b-2ac8-4491-afad-d748080e2d55"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]}],"source":["#from transformers import AutoTokenizer,BertTokenizerFast, BertTokenizer, AdamW, BertForQuestionAnswering\n","#tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")懶人用法\n","#tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","#tokenizer_fast = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n","#from transformers import BertTokenizer, BertForSequenceClassification\n","\n","#tokenizer = BertTokenizer.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\")\n","from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1224,"status":"ok","timestamp":1685259621825,"user":{"displayName":"許家紳","userId":"14766431505425888321"},"user_tz":-480},"id":"SSM_2cPVLSDm","outputId":"ae6c337b-ba40-494b-f7c0-e8e40b8c5b47"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5TokenizerFast(name_or_path='google/mt5-small', vocab_size=250100, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=True)"]},"metadata":{},"execution_count":12}],"source":["tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6025,"status":"ok","timestamp":1685259627844,"user":{"displayName":"許家紳","userId":"14766431505425888321"},"user_tz":-480},"id":"HVZ93MuMJiuQ","outputId":"b41fde3b-c70b-4aec-8252-a3f3a1f08d9f"},"outputs":[{"output_type":"stream","name":"stderr","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","IOPub data rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_data_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n"]}],"source":["train_encodings = tokenizer(train_sen1, train_sen2, truncation=True, padding=True)\n","print(train_encodings)\n","eval_encodings = tokenizer(eval_sen1, eval_sen2, truncation=True, padding=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1685259627844,"user":{"displayName":"許家紳","userId":"14766431505425888321"},"user_tz":-480},"id":"ie2ZIlJ8NKPK","outputId":"d36c4fe0-8adf-43c2-c06f-3aa3cffa6511"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['input_ids', 'attention_mask'])"]},"metadata":{},"execution_count":14}],"source":["train_encodings.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e7CXhViiNftW"},"outputs":[],"source":["#print(tokenizer.decode(train_encodings['input_ids'][0]))\n","#print(train_encodings['input_ids'][0])\n","#print(\"token_type_ids\\n\", train_encodings['token_type_ids'][0])\n","#print(\"attention_mask\\n\", train_encodings['attention_mask'][0])\n","\n","#print(len(train_encodings['input_ids'][0]))\n","#print(len(train_encodings['token_type_ids'][0]))"]},{"cell_type":"markdown","metadata":{"id":"2JefrKPM-hpu"},"source":["## 加入label(答案)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S1_cvVW1-kRN"},"outputs":[],"source":["def add_targets(encodings,label):\n","    encodings.update({'labels':label})\n","add_targets(train_encodings,trainlabel)\n","add_targets(eval_encodings,evallabel)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4454,"status":"ok","timestamp":1685259632295,"user":{"displayName":"許家紳","userId":"14766431505425888321"},"user_tz":-480},"id":"cmwWT191_M1O","outputId":"bd760eef-8a40-4e7f-f85c-d6977497a21b"},"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['input_ids', 'attention_mask', 'labels'])\n","</s><pad><pad></s></s></s></s></s><pad></s></s></s></s><pad><pad></s><pad><pad><pad></s></s><pad></s></s><pad></s></s></s></s></s><pad><pad></s><pad></s><pad><pad></s></s></s></s><pad></s></s></s></s></s><pad></s><pad><pad></s><pad><pad></s><pad></s><pad><pad></s><pad></s></s></s></s><pad><pad></s><pad></s></s><pad></s></s></s><pad><pad><pad></s><pad></s></s><pad></s></s><pad><pad></s><pad><pad></s><pad><pad></s></s></s></s></s></s><pad></s></s><pad></s><pad></s></s><pad></s><pad><pad><pad></s></s><pad></s><pad><pad></s></s><pad></s><pad></s></s><pad><pad></s></s></s><pad><pad></s><pad><pad></s><pad><pad></s><pad></s></s><pad><pad></s></s><pad><pad></s><pad></s></s><pad><pad><pad></s></s><pad></s></s><pad></s></s></s></s><pad></s></s><pad></s></s><pad><pad></s><pad></s></s></s><pad></s></s><pad></s></s></s><pad><pad></s><pad></s><pad><pad></s></s><pad><pad></s><pad><pad><pad></s></s><pad><pad><pad></s><pad><pad><pad><pad></s></s><pad><pad></s><pad></s></s></s></s></s></s></s></s></s></s></s><pad><pad></s><pad></s></s></s><pad></s><pad><pad><pad><pad><pad></s><pad></s></s><pad><pad></s></s></s><pad><pad><pad><pad><pad><pad><pad></s></s><pad><pad></s></s><pad><pad></s><pad></s></s><pad><pad></s><pad></s><pad></s><pad><pad></s></s></s></s></s></s></s></s><pad></s></s></s><pad></s></s><pad></s><pad><pad><pad></s></s></s></s></s><pad></s></s><pad></s><pad><pad></s></s></s></s></s></s><pad></s><pad></s></s></s><pad><pad></s><pad><pad><pad><pad></s><pad></s><pad></s></s></s><pad></s></s><pad><pad></s><pad><pad></s></s></s><pad><pad><pad></s></s><pad><pad></s></s></s><pad><pad></s></s><pad><pad></s></s><pad><pad></s><pad></s><pad><pad><pad><pad></s><pad><pad></s></s></s></s></s><pad><pad></s><pad></s></s></s></s></s><pad></s><pad><pad></s><pad></s><pad></s></s></s><pad></s></s><pad><pad><pad></s><pad></s><pad></s></s></s></s></s></s></s><pad><pad></s><pad></s></s><pad></s></s><pad><pad></s><pad></s><pad><pad></s><pad></s><pad><pad><pad></s></s><pad></s><pad><pad></s><pad><pad><pad></s></s></s></s></s></s><pad><pad><pad><pad></s><pad><pad></s></s><pad><pad></s></s></s><pad><pad></s></s><pad><pad><pad></s></s><pad><pad><pad><pad></s><pad></s></s><pad></s></s><pad><pad></s><pad></s></s></s></s></s></s></s></s><pad></s></s></s><pad><pad><pad></s><pad></s></s><pad><pad><pad></s></s><pad><pad></s></s></s></s></s></s><pad><pad></s></s></s><pad></s></s><pad><pad></s><pad></s></s></s><pad></s></s><pad><pad></s><pad></s></s></s><pad></s><pad><pad></s><pad></s></s></s></s></s></s><pad></s><pad></s></s></s></s><pad></s><pad></s><pad><pad><pad><pad></s><pad><pad><pad></s></s><pad><pad></s><pad><pad></s></s><pad><pad></s></s><pad></s></s><pad><pad></s></s></s><pad></s><pad><pad><pad></s></s><pad></s></s><pad><pad></s></s></s><pad></s></s></s></s><pad></s></s></s></s><pad></s></s></s><pad></s><pad><pad></s></s><pad></s></s></s><pad></s></s></s></s></s></s></s><pad></s><pad><pad><pad><pad></s></s></s></s></s></s></s></s></s><pad><pad><pad><pad><pad><pad><pad></s><pad><pad></s><pad></s></s><pad></s></s></s></s><pad></s><pad></s></s></s></s></s><pad><pad><pad><pad></s><pad></s></s></s><pad><pad></s></s></s><pad></s></s><pad><pad><pad></s></s></s></s></s></s></s><pad><pad></s><pad></s></s><pad></s></s><pad><pad><pad><pad><pad><pad><pad></s><pad></s></s><pad><pad></s><pad></s><pad></s></s></s></s><pad><pad></s></s></s></s><pad></s></s></s><pad></s></s></s></s></s></s></s><pad><pad></s><pad><pad><pad><pad><pad><pad></s></s><pad><pad><pad></s><pad><pad></s></s><pad><pad><pad><pad></s></s><pad><pad></s></s></s></s><pad></s><pad></s></s></s></s><pad></s></s></s><pad></s></s><pad></s></s><pad><pad><pad></s></s></s><pad><pad></s></s><pad><pad><pad></s><pad><pad><pad><pad><pad></s></s><pad><pad></s></s><pad></s></s></s></s></s></s></s></s></s></s></s></s><pad><pad><pad></s><pad><pad><pad></s><pad></s></s><pad></s></s><pad></s></s></s></s><pad></s><pad></s><pad></s><pad><pad></s></s></s><pad></s></s></s></s></s></s></s><pad><pad></s></s><pad></s><pad><pad></s></s><pad><pad><pad><pad></s></s></s></s><pad></s></s></s></s></s></s></s></s><pad><pad><pad><pad></s></s></s></s><pad></s></s><pad><pad><pad></s><pad></s><pad></s><pad></s><pad></s></s></s></s></s></s></s><pad></s><pad></s></s></s></s><pad></s></s></s></s></s><pad></s></s></s></s></s></s></s></s></s><pad><pad><pad></s></s><pad></s><pad></s><pad></s><pad><pad><pad></s></s><pad></s></s><pad></s></s><pad><pad></s></s></s></s><pad><pad></s><pad></s></s></s></s></s><pad></s><pad></s><pad></s></s></s><pad></s></s><pad></s><pad></s><pad><pad></s><pad></s></s></s></s></s><pad><pad><pad><pad><pad></s></s></s><pad><pad></s><pad></s></s></s></s><pad></s><pad><pad></s></s><pad></s></s></s><pad><pad><pad><pad></s></s><pad></s><pad></s></s></s><pad><pad></s><pad></s></s><pad><pad></s></s><pad></s><pad></s></s></s><pad><pad><pad><pad><pad></s></s></s></s><pad></s></s><pad></s></s></s><pad><pad><pad><pad></s></s><pad></s></s></s></s><pad></s><pad><pad></s></s></s></s><pad></s><pad><pad></s><pad></s></s></s></s></s><pad><pad></s></s><pad></s></s><pad><pad><pad><pad></s></s></s></s></s></s></s><pad></s><pad></s><pad><pad><pad></s></s><pad><pad><pad><pad><pad></s><pad></s></s></s><pad><pad></s><pad><pad><pad><pad></s></s><pad></s></s><pad></s></s></s></s><pad></s></s><pad></s><pad><pad><pad></s></s></s></s></s><pad></s><pad><pad><pad><pad><pad><pad><pad><pad></s><pad></s><pad></s></s></s><pad><pad></s><pad><pad></s></s></s><pad></s><pad><pad><pad></s></s><pad></s></s></s></s><pad></s></s><pad><pad><pad></s></s></s></s></s><pad><pad><pad><pad></s><pad><pad><pad><pad><pad></s></s><pad></s></s></s></s><pad><pad></s></s></s></s><pad></s><pad></s><pad></s></s></s></s><pad></s></s><pad></s><pad></s><pad><pad><pad></s></s><pad></s></s></s><pad><pad></s></s></s></s></s><pad></s><pad><pad><pad></s><pad></s><pad></s></s><pad><pad></s></s></s><pad></s></s><pad></s></s></s><pad><pad><pad><pad></s></s><pad></s></s><pad></s></s></s></s><pad></s></s></s><pad></s></s></s></s></s></s></s></s></s><pad><pad></s></s></s><pad><pad></s></s><pad><pad></s><pad></s></s></s><pad></s><pad></s></s></s><pad></s></s></s><pad><pad><pad><pad></s><pad></s><pad></s></s><pad><pad></s></s></s></s><pad></s></s><pad><pad></s></s><pad></s></s><pad><pad></s><pad><pad><pad></s></s><pad><pad></s><pad></s></s><pad><pad><pad><pad></s></s><pad></s><pad></s><pad></s><pad></s></s></s></s></s></s><pad><pad><pad></s></s><pad><pad></s><pad></s><pad></s><pad></s></s><pad><pad><pad><pad><pad></s></s><pad></s></s><pad></s></s></s><pad><pad><pad></s><pad><pad><pad></s><pad><pad><pad></s></s></s></s></s></s></s><pad></s></s></s><pad><pad></s></s><pad></s><pad></s></s></s></s><pad></s></s><pad><pad></s></s><pad><pad></s><pad><pad></s></s><pad></s></s><pad></s></s><pad></s></s></s></s></s></s></s><pad></s></s></s><pad><pad></s><pad><pad></s><pad></s></s></s></s></s></s><pad><pad></s><pad><pad></s><pad></s><pad></s><pad></s></s></s></s></s></s><pad><pad><pad></s><pad></s><pad><pad><pad></s><pad></s><pad></s></s></s></s></s></s><pad></s></s></s></s></s><pad><pad><pad></s><pad><pad></s></s><pad><pad></s></s><pad></s></s><pad></s><pad></s></s></s></s></s></s><pad></s></s><pad></s></s><pad></s></s><pad></s><pad></s><pad><pad></s><pad><pad></s><pad><pad></s></s></s><pad></s></s><pad></s><pad><pad></s><pad><pad></s></s><pad><pad><pad><pad></s></s></s><pad></s></s><pad><pad></s><pad></s></s></s></s></s></s><pad><pad></s></s></s></s></s></s></s></s></s><pad><pad></s></s></s></s><pad></s><pad><pad><pad></s><pad></s></s><pad></s><pad></s></s></s></s></s></s><pad></s></s></s><pad><pad></s><pad><pad><pad><pad><pad><pad></s><pad></s><pad><pad><pad></s><pad></s></s></s></s><pad></s><pad><pad><pad><pad></s></s><pad><pad><pad></s><pad></s></s></s></s></s><pad><pad><pad><pad></s></s></s><pad></s><pad></s></s></s></s><pad></s></s><pad><pad></s></s><pad></s></s></s></s><pad></s></s></s></s><pad></s><pad><pad></s><pad></s><pad><pad></s></s></s><pad></s></s></s></s></s></s><pad></s></s></s></s><pad><pad></s><pad><pad><pad></s><pad></s></s></s><pad></s></s></s></s></s></s><pad><pad><pad></s></s></s></s><pad><pad></s></s></s></s></s><pad><pad></s></s><pad><pad><pad></s></s><pad><pad><pad><pad></s></s></s><pad><pad><pad></s><pad></s></s><pad></s><pad></s></s></s><pad></s></s><pad><pad><pad><pad></s></s><pad><pad></s></s></s><pad><pad><pad><pad></s><pad></s></s><pad></s></s></s></s><pad><pad></s></s></s><pad><pad><pad><pad><pad></s></s><pad><pad><pad></s><pad></s><pad><pad><pad></s></s></s><pad><pad><pad></s><pad><pad></s></s><pad></s><pad></s></s></s><pad></s></s><pad><pad><pad></s></s></s></s></s></s></s></s></s><pad><pad></s></s><pad><pad></s><pad><pad></s></s><pad></s><pad></s></s></s></s></s><pad></s><pad><pad></s><pad></s><pad></s></s><pad></s></s><pad></s></s></s></s><pad></s></s></s></s><pad></s><pad><pad><pad></s></s><pad><pad></s><pad></s></s></s></s><pad></s></s><pad><pad></s><pad></s></s><pad><pad></s></s></s></s><pad><pad></s></s></s></s></s></s><pad><pad></s></s><pad><pad><pad></s></s></s><pad></s></s><pad></s><pad></s><pad></s><pad></s></s><pad></s><pad></s><pad></s></s></s></s><pad></s><pad></s><pad></s></s><pad><pad><pad></s></s><pad></s><pad></s></s></s><pad><pad></s></s><pad></s><pad><pad><pad></s></s></s><pad></s></s></s><pad></s></s></s></s><pad></s></s><pad><pad></s></s><pad></s><pad></s><pad></s><pad></s><pad><pad></s><pad></s></s></s></s></s></s></s><pad><pad><pad></s></s></s><pad></s></s><pad><pad><pad></s><pad></s></s><pad><pad><pad><pad></s><pad></s><pad></s><pad><pad></s></s><pad></s><pad><pad><pad></s><pad></s></s><pad><pad></s><pad><pad><pad></s></s><pad></s><pad><pad><pad><pad></s></s><pad></s></s></s><pad></s></s><pad><pad></s></s><pad></s><pad></s></s></s><pad><pad></s><pad><pad><pad></s><pad></s><pad><pad></s><pad></s><pad></s><pad></s></s></s><pad><pad></s><pad><pad></s><pad></s><pad></s></s></s><pad></s></s><pad><pad></s></s><pad></s></s><pad></s><pad><pad></s><pad></s><pad></s></s></s><pad></s></s></s><pad></s><pad></s><pad><pad><pad></s></s></s><pad></s><pad><pad></s></s></s><pad></s></s></s></s></s><pad></s><pad></s><pad><pad></s></s></s></s></s><pad><pad><pad></s><pad></s></s><pad><pad></s><pad><pad></s><pad><pad><pad><pad></s><pad></s></s></s></s></s><pad></s></s></s><pad><pad></s></s></s><pad><pad></s><pad></s><pad></s><pad></s></s><pad></s><pad><pad></s></s></s><pad><pad></s><pad></s></s><pad><pad></s></s><pad></s></s></s><pad></s><pad></s><pad></s><pad><pad><pad></s></s></s></s></s></s></s></s><pad><pad></s></s><pad><pad></s></s></s><pad><pad><pad></s></s></s><pad><pad></s><pad></s></s><pad></s></s></s><pad></s><pad></s><pad></s><pad></s><pad></s><pad><pad></s><pad></s></s></s></s></s><pad><pad></s></s></s><pad></s><pad></s></s><pad><pad><pad></s></s></s></s></s></s></s><pad></s></s><pad><pad></s></s><pad><pad><pad></s><pad></s><pad></s></s></s></s></s><pad></s></s><pad></s></s><pad></s><pad><pad><pad></s><pad></s><pad><pad></s><pad></s><pad><pad><pad></s></s><pad><pad></s><pad></s></s></s></s><pad></s></s><pad><pad></s></s></s></s></s><pad></s><pad><pad><pad></s><pad><pad><pad></s></s><pad></s><pad><pad></s><pad></s><pad><pad></s><pad><pad></s></s></s><pad><pad></s><pad></s></s><pad><pad></s></s><pad></s><pad></s><pad><pad><pad></s><pad><pad></s></s><pad></s><pad><pad></s></s></s></s></s></s><pad></s><pad><pad></s></s></s><pad><pad></s></s></s></s></s></s></s></s></s><pad></s></s></s><pad></s></s></s><pad><pad></s><pad></s></s></s><pad></s></s></s></s><pad></s></s></s><pad><pad></s></s></s><pad><pad><pad></s></s><pad><pad><pad></s></s></s></s><pad></s><pad><pad></s></s></s></s></s><pad><pad></s></s></s></s><pad></s></s></s></s></s><pad><pad><pad></s></s><pad><pad></s></s><pad><pad></s></s><pad></s></s></s><pad></s></s></s><pad></s></s></s></s><pad></s><pad><pad></s><pad><pad><pad></s><pad></s></s></s></s></s></s><pad><pad></s></s></s><pad><pad></s><pad><pad><pad></s><pad></s><pad></s><pad><pad><pad></s><pad><pad></s><pad><pad></s></s></s><pad></s></s></s><pad></s></s></s><pad><pad><pad><pad></s></s></s><pad><pad><pad><pad><pad><pad></s></s></s><pad></s></s></s></s></s></s></s><pad></s><pad><pad><pad></s><pad></s></s></s><pad><pad></s></s><pad></s><pad><pad><pad></s><pad></s></s></s></s></s><pad><pad><pad></s></s><pad></s></s><pad><pad></s></s><pad></s></s></s></s><pad><pad><pad><pad></s><pad></s></s><pad></s><pad><pad></s></s><pad><pad></s></s></s></s><pad></s></s></s><pad><pad><pad><pad></s><pad></s></s></s></s></s></s><pad></s><pad><pad><pad></s><pad><pad></s><pad></s></s><pad><pad></s></s></s></s><pad><pad><pad><pad></s></s><pad><pad><pad></s></s><pad></s><pad></s></s><pad><pad></s></s><pad></s></s></s><pad></s><pad></s><pad></s></s><pad></s></s></s></s></s></s></s><pad></s><pad><pad><pad><pad><pad><pad></s><pad></s></s><pad></s></s><pad><pad><pad><pad></s></s><pad><pad><pad><pad></s></s></s><pad><pad><pad></s><pad><pad></s></s></s></s></s></s></s></s><pad><pad><pad><pad><pad></s></s><pad><pad></s></s></s></s><pad></s></s></s></s></s></s><pad></s></s><pad><pad></s><pad></s></s></s><pad><pad></s><pad><pad></s></s></s></s></s></s><pad><pad><pad><pad></s></s></s></s></s></s></s></s><pad><pad></s></s></s><pad></s><pad></s></s></s></s></s><pad><pad><pad><pad><pad><pad></s></s></s><pad></s></s></s></s></s></s></s><pad><pad></s></s></s><pad><pad></s></s><pad><pad><pad><pad><pad><pad></s></s></s><pad><pad></s></s><pad></s></s><pad><pad></s><pad><pad></s></s></s></s><pad></s><pad></s><pad></s></s></s><pad></s><pad></s></s></s><pad><pad></s><pad><pad><pad><pad></s><pad><pad></s></s></s></s><pad></s><pad></s></s><pad></s><pad><pad><pad></s><pad><pad></s><pad></s></s></s></s></s></s></s><pad></s><pad><pad></s></s><pad><pad></s></s><pad><pad><pad><pad><pad></s><pad><pad><pad></s></s><pad><pad></s><pad><pad></s></s></s></s></s></s></s></s><pad></s></s><pad><pad><pad><pad><pad><pad><pad></s><pad></s><pad><pad><pad></s></s><pad></s></s></s></s></s><pad><pad><pad></s></s></s><pad></s><pad></s></s><pad></s></s></s><pad><pad><pad><pad></s><pad></s><pad><pad></s><pad></s><pad></s></s><pad><pad></s></s><pad></s></s></s></s><pad></s></s></s><pad><pad></s></s><pad><pad><pad></s><pad><pad></s></s></s></s></s><pad><pad></s></s><pad><pad></s></s><pad></s></s><pad><pad></s></s></s></s></s></s><pad><pad><pad></s><pad></s></s></s></s><pad></s></s></s></s></s></s><pad></s><pad><pad><pad><pad></s></s></s></s></s></s></s><pad><pad><pad><pad></s></s></s></s><pad><pad><pad></s><pad></s><pad><pad><pad></s></s></s></s></s></s><pad><pad><pad></s></s><pad></s></s><pad><pad></s><pad><pad><pad><pad></s></s></s></s></s><pad><pad></s><pad><pad></s><pad><pad><pad><pad></s></s><pad></s></s><pad><pad></s></s><pad><pad></s></s><pad><pad><pad><pad></s></s></s><pad></s></s></s></s></s></s><pad><pad><pad><pad><pad></s><pad></s></s><pad><pad></s><pad></s><pad></s></s></s></s></s><pad><pad></s><pad><pad><pad><pad></s><pad></s></s></s></s></s><pad><pad></s><pad></s></s><pad><pad></s></s></s><pad></s></s><pad></s></s><pad></s></s></s></s></s></s></s></s><pad></s><pad><pad></s></s></s></s><pad><pad></s></s><pad></s><pad></s></s></s></s></s></s></s></s></s><pad></s><pad></s></s></s></s></s></s></s><pad></s><pad><pad></s></s></s></s></s><pad></s></s></s><pad></s><pad></s></s><pad></s></s></s></s><pad></s></s><pad><pad><pad></s><pad></s><pad><pad></s></s><pad><pad></s></s></s><pad></s><pad></s></s><pad><pad></s></s></s></s><pad></s><pad></s><pad></s><pad><pad></s></s></s></s></s><pad><pad><pad><pad></s></s></s><pad></s></s></s><pad><pad><pad><pad><pad></s></s></s></s><pad></s><pad></s><pad><pad></s><pad><pad></s></s></s></s></s><pad><pad></s></s></s><pad></s></s></s></s></s><pad></s></s><pad><pad><pad><pad><pad><pad><pad><pad><pad></s><pad></s></s><pad><pad><pad></s></s></s></s></s></s></s></s><pad><pad><pad></s><pad><pad><pad><pad></s></s><pad></s></s></s></s></s></s></s><pad><pad><pad><pad></s></s><pad><pad></s><pad></s></s></s><pad></s><pad></s></s></s></s></s><pad><pad></s></s><pad></s></s></s></s><pad></s></s><pad></s></s></s></s></s></s><pad><pad></s></s><pad><pad></s><pad></s><pad><pad><pad></s><pad></s></s></s></s><pad></s><pad><pad><pad></s><pad></s><pad></s><pad><pad></s></s><pad><pad><pad><pad></s></s></s><pad></s></s><pad><pad></s></s><pad><pad></s></s></s></s></s></s></s></s></s></s><pad><pad></s></s><pad><pad><pad><pad><pad><pad><pad><pad></s><pad></s></s></s><pad></s></s></s><pad></s><pad><pad></s></s></s><pad><pad><pad></s></s></s><pad></s><pad><pad><pad></s><pad></s><pad></s></s></s></s></s></s></s></s></s></s></s></s></s><pad></s></s></s></s><pad><pad><pad><pad></s></s><pad></s></s></s></s></s></s></s></s></s><pad></s><pad></s><pad><pad><pad></s></s></s><pad><pad><pad></s></s></s></s></s></s></s><pad><pad></s><pad></s></s><pad></s><pad><pad></s></s></s></s><pad><pad></s></s><pad></s><pad></s></s></s></s><pad><pad><pad></s></s></s></s></s><pad><pad></s></s><pad></s><pad><pad><pad><pad></s></s></s><pad><pad></s></s></s></s></s></s></s></s><pad></s></s></s></s></s><pad></s><pad></s></s></s></s></s><pad></s><pad></s></s><pad></s><pad></s></s><pad></s><pad></s></s></s><pad><pad></s></s><pad></s><pad><pad><pad><pad><pad></s><pad><pad></s></s><pad><pad></s></s></s></s></s></s><pad></s><pad><pad><pad></s></s><pad><pad></s><pad></s><pad><pad></s></s></s><pad><pad><pad></s><pad><pad><pad><pad><pad><pad></s></s><pad></s></s><pad><pad></s><pad><pad><pad><pad></s><pad><pad><pad><pad><pad><pad></s><pad><pad></s><pad></s></s></s></s></s></s></s></s></s><pad></s></s><pad></s><pad></s><pad></s><pad><pad><pad><pad><pad></s><pad><pad><pad><pad></s><pad><pad><pad><pad></s></s><pad></s></s></s><pad><pad></s><pad></s></s></s><pad></s><pad></s></s></s><pad><pad></s><pad><pad><pad></s></s></s></s><pad></s><pad></s><pad><pad></s><pad><pad></s><pad></s></s><pad></s><pad></s><pad></s><pad><pad></s><pad><pad></s><pad><pad><pad><pad><pad></s></s></s></s><pad><pad><pad></s></s><pad></s><pad></s><pad></s></s></s></s><pad></s><pad><pad><pad><pad></s><pad><pad><pad><pad></s></s></s><pad></s><pad></s><pad><pad><pad><pad><pad></s><pad></s></s><pad></s></s></s></s><pad></s><pad></s></s></s></s><pad></s></s></s></s></s><pad></s><pad></s><pad><pad></s><pad></s><pad><pad><pad><pad></s></s></s><pad></s><pad><pad><pad></s></s></s></s><pad><pad></s></s></s></s><pad></s></s></s><pad></s><pad></s><pad></s><pad><pad><pad><pad><pad><pad></s></s></s><pad><pad></s><pad><pad></s></s><pad><pad><pad></s><pad></s><pad><pad><pad></s><pad></s><pad></s><pad></s><pad><pad></s></s><pad></s><pad></s><pad><pad></s></s><pad><pad></s><pad></s><pad></s><pad><pad></s><pad></s></s></s></s></s><pad></s></s></s><pad></s><pad></s><pad></s><pad></s></s></s><pad><pad><pad></s></s></s><pad></s><pad></s><pad></s><pad><pad></s></s><pad><pad></s></s></s><pad><pad></s><pad></s></s></s></s></s></s></s></s></s></s></s><pad><pad><pad></s></s><pad><pad></s></s></s></s></s><pad><pad></s><pad><pad><pad></s><pad></s></s><pad></s></s><pad><pad><pad><pad><pad></s></s></s></s><pad></s></s><pad><pad><pad></s></s><pad></s></s><pad></s></s></s></s></s><pad><pad><pad></s></s></s></s><pad><pad></s><pad><pad></s><pad></s></s></s><pad><pad><pad></s></s><pad><pad><pad><pad></s></s></s></s><pad></s></s><pad><pad><pad><pad><pad></s><pad></s><pad></s></s><pad><pad></s></s></s><pad></s><pad><pad></s></s><pad></s><pad></s><pad></s><pad></s><pad><pad></s><pad><pad><pad></s></s></s><pad></s></s></s></s></s></s></s><pad><pad><pad></s><pad><pad><pad><pad><pad><pad></s></s></s></s></s></s></s></s><pad><pad><pad></s><pad></s><pad></s></s></s></s></s><pad><pad></s><pad><pad></s></s></s></s></s><pad><pad></s></s></s></s></s></s></s><pad></s><pad></s></s></s><pad></s></s><pad><pad></s></s><pad></s></s></s></s><pad><pad></s></s></s><pad><pad></s></s></s><pad><pad><pad><pad><pad></s><pad><pad></s></s><pad></s></s></s></s></s></s><pad></s></s><pad></s><pad></s><pad></s><pad></s></s></s></s><pad></s></s></s><pad></s><pad></s></s><pad></s><pad><pad></s></s></s><pad></s><pad><pad></s></s></s></s><pad></s><pad></s></s></s><pad></s></s></s><pad><pad></s><pad></s></s><pad><pad><pad><pad><pad></s></s><pad><pad><pad><pad><pad></s><pad></s></s></s></s></s></s><pad><pad></s><pad><pad></s></s></s><pad><pad><pad></s></s><pad></s><pad><pad></s></s><pad></s></s></s></s><pad></s><pad></s></s></s></s></s><pad></s></s><pad><pad></s></s></s><pad></s></s><pad></s><pad><pad></s><pad></s></s></s></s></s></s></s></s><pad></s></s></s><pad><pad><pad></s></s></s></s></s></s><pad></s><pad></s></s><pad></s><pad></s><pad></s><pad></s><pad><pad></s></s></s><pad><pad><pad><pad><pad><pad></s><pad><pad></s><pad></s></s></s></s><pad><pad></s></s><pad><pad></s></s><pad></s></s></s></s><pad><pad><pad><pad></s></s><pad></s></s></s><pad></s><pad></s></s><pad></s><pad><pad><pad><pad><pad><pad></s></s></s><pad><pad></s><pad></s></s></s></s><pad><pad><pad><pad><pad></s><pad></s></s></s></s></s></s><pad><pad><pad></s><pad><pad><pad></s></s></s></s></s></s><pad><pad><pad></s></s><pad></s><pad><pad></s><pad></s></s><pad></s></s></s><pad><pad></s></s><pad><pad></s><pad></s></s></s></s></s><pad><pad><pad></s></s><pad></s><pad></s></s><pad></s><pad><pad></s></s></s></s><pad></s><pad></s><pad></s></s></s></s><pad></s><pad></s></s></s><pad></s></s><pad><pad></s><pad><pad></s><pad><pad></s></s><pad></s></s><pad><pad></s><pad></s><pad></s><pad><pad></s></s><pad></s></s></s><pad></s><pad></s></s></s></s><pad><pad></s><pad></s></s></s></s><pad><pad></s><pad></s></s><pad></s></s><pad><pad></s></s><pad></s></s><pad></s></s><pad><pad></s></s><pad><pad><pad><pad><pad><pad></s></s><pad></s><pad></s><pad><pad></s></s></s><pad><pad></s></s></s></s><pad><pad></s></s><pad></s></s><pad><pad></s></s><pad></s></s></s><pad></s></s></s></s></s></s></s></s></s><pad></s><pad></s></s></s><pad><pad><pad><pad></s><pad></s><pad><pad></s></s></s></s><pad></s></s></s></s></s></s><pad><pad><pad></s></s><pad><pad></s></s></s></s></s></s><pad></s></s><pad></s></s></s></s></s><pad><pad></s><pad></s></s><pad></s></s><pad><pad></s></s></s></s><pad></s></s></s></s></s></s><pad></s></s></s></s></s><pad></s></s></s></s><pad></s><pad><pad><pad><pad><pad><pad><pad></s></s></s></s></s><pad></s></s></s></s></s></s><pad></s></s><pad></s><pad><pad></s><pad><pad></s><pad></s><pad></s></s><pad></s><pad></s></s></s></s></s></s></s><pad></s><pad><pad></s></s></s></s></s></s></s></s><pad><pad><pad></s></s><pad></s></s><pad></s><pad></s></s><pad></s><pad><pad></s><pad></s><pad><pad><pad><pad><pad></s><pad><pad></s><pad></s><pad></s><pad></s><pad><pad><pad></s><pad><pad><pad></s><pad></s></s></s><pad><pad></s><pad></s><pad></s></s><pad></s><pad><pad><pad><pad></s></s><pad></s><pad></s><pad></s></s><pad></s></s><pad><pad><pad></s><pad></s></s><pad><pad><pad></s><pad></s></s><pad><pad></s></s></s><pad><pad></s></s></s></s></s></s></s><pad></s><pad><pad></s><pad></s><pad><pad></s><pad></s></s></s></s></s></s><pad><pad><pad><pad></s><pad></s></s></s><pad></s><pad></s><pad></s></s></s><pad><pad><pad><pad><pad></s></s></s></s></s></s></s></s></s></s></s></s></s><pad></s></s></s></s></s><pad></s></s></s></s><pad><pad></s></s><pad></s></s></s><pad></s></s></s></s></s></s><pad><pad><pad><pad><pad><pad></s></s></s><pad><pad></s><pad></s><pad><pad><pad></s></s></s><pad></s></s><pad><pad></s><pad></s><pad><pad></s><pad></s><pad><pad></s><pad></s></s></s><pad></s><pad></s><pad></s></s></s><pad></s><pad></s><pad><pad></s><pad></s><pad><pad><pad><pad></s><pad></s></s><pad></s></s></s></s></s></s></s><pad><pad></s></s></s><pad></s></s><pad></s></s></s></s></s><pad></s></s></s><pad><pad><pad><pad><pad></s></s><pad><pad><pad></s><pad></s><pad><pad><pad></s><pad></s></s></s></s></s></s></s></s></s></s></s></s><pad><pad></s><pad></s><pad></s><pad></s><pad></s><pad></s><pad></s><pad></s></s><pad></s></s></s><pad></s><pad><pad><pad><pad><pad><pad><pad><pad></s></s><pad></s><pad><pad><pad></s></s><pad><pad></s><pad></s></s><pad></s></s></s></s></s><pad></s></s><pad></s><pad><pad></s><pad><pad></s></s></s><pad></s><pad><pad><pad><pad></s></s></s></s></s><pad></s></s></s></s><pad></s></s><pad></s><pad></s></s></s><pad><pad><pad><pad></s></s><pad></s></s></s><pad></s><pad></s><pad></s></s></s></s><pad></s><pad></s></s><pad><pad></s></s><pad></s></s><pad><pad></s></s></s></s><pad><pad><pad><pad><pad></s></s><pad><pad></s></s></s><pad></s><pad><pad></s></s></s><pad></s></s></s><pad><pad><pad></s><pad><pad></s></s><pad></s><pad></s></s><pad><pad><pad><pad><pad><pad><pad></s></s></s><pad></s><pad><pad></s><pad></s><pad></s></s><pad></s><pad></s></s><pad></s></s></s><pad><pad><pad><pad><pad></s></s><pad><pad><pad><pad><pad><pad><pad></s><pad></s><pad></s></s></s></s><pad><pad></s><pad><pad></s></s><pad><pad><pad><pad></s><pad><pad><pad></s></s></s></s></s></s><pad><pad></s></s></s></s></s><pad><pad><pad></s></s><pad><pad></s><pad></s><pad></s></s><pad></s><pad><pad></s><pad></s></s></s><pad><pad><pad></s><pad></s></s></s><pad></s></s></s></s></s></s></s></s><pad></s><pad></s></s></s><pad><pad></s><pad><pad></s>\n"]}],"source":["print(train_encodings.keys())\n","print(tokenizer.decode(train_encodings['labels']))"]},{"cell_type":"markdown","metadata":{"id":"46O8l82OABGo"},"source":["# 定義dataset 並轉換成tensor格式\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r39lVT_rA1wE"},"outputs":[],"source":["\n","from torch.utils import data\n","import torch\n","\n","class Dataset(torch.utils.data.Dataset):\n","  def __init__(self, encodings):\n","    self.encodings = encodings\n","\n","  def __getitem__(self, idx):\n","    return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n","\n","  def __len__(self):\n","    return len(self.encodings.input_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2dbNJH1YA3sm"},"outputs":[],"source":["train_dataset = Dataset(train_encodings)\n","eval_dataset = Dataset(eval_encodings)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1685259632296,"user":{"displayName":"許家紳","userId":"14766431505425888321"},"user_tz":-480},"id":"rP7evERNA86Y","outputId":"ae1fff4f-8dc6-48c3-d960-046cfe1f473f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([  259, 32030, 17225,  ...,     0,     0,     0]),\n"," 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]),\n"," 'labels': tensor(1)}"]},"metadata":{},"execution_count":20}],"source":["train_dataset[0]"]},{"cell_type":"markdown","metadata":{"id":"6C4LEeWaBHnO"},"source":["# 載入模型架構"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"81zW1XF9BHNO"},"outputs":[],"source":["from transformers import MT5Config,MT5Model,MT5ForConditionalGeneration,AutoModelForSeq2SeqLM\n","config = MT5Config.from_pretrained('google/mt5-small', num_labels=2)  #num_labels 設定類別數\n","model =  MT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1685259646647,"user":{"displayName":"許家紳","userId":"14766431505425888321"},"user_tz":-480},"id":"iA3F-EnbB0s3","outputId":"e9724740-b65f-41c2-8f98-30e3e0c5b2cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["MT5ForConditionalGeneration(\n","  (shared): Embedding(250112, 512)\n","  (encoder): MT5Stack(\n","    (embed_tokens): Embedding(250112, 512)\n","    (block): ModuleList(\n","      (0): MT5Block(\n","        (layer): ModuleList(\n","          (0): MT5LayerSelfAttention(\n","            (SelfAttention): MT5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 6)\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): MT5LayerFF(\n","            (DenseReluDense): MT5DenseGatedActDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-7): 7 x MT5Block(\n","        (layer): ModuleList(\n","          (0): MT5LayerSelfAttention(\n","            (SelfAttention): MT5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): MT5LayerFF(\n","            (DenseReluDense): MT5DenseGatedActDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): MT5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): MT5Stack(\n","    (embed_tokens): Embedding(250112, 512)\n","    (block): ModuleList(\n","      (0): MT5Block(\n","        (layer): ModuleList(\n","          (0): MT5LayerSelfAttention(\n","            (SelfAttention): MT5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 6)\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): MT5LayerCrossAttention(\n","            (EncDecAttention): MT5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): MT5LayerFF(\n","            (DenseReluDense): MT5DenseGatedActDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-7): 7 x MT5Block(\n","        (layer): ModuleList(\n","          (0): MT5LayerSelfAttention(\n","            (SelfAttention): MT5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): MT5LayerCrossAttention(\n","            (EncDecAttention): MT5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): MT5LayerFF(\n","            (DenseReluDense): MT5DenseGatedActDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): MT5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=512, out_features=250112, bias=False)\n",")\n"]}],"source":["print(model)"]},{"cell_type":"markdown","metadata":{"id":"0XGFIfIKCFPo"},"source":["## 該來訓練模型囉"]},{"cell_type":"code","source":["#import gc\n","#torch.cuda.empty_cache()\n","#gc.collect()"],"metadata":{"id":"DfVo-fVKjCEa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!ps -aux|grep python"],"metadata":{"id":"rv1AtvfeCs0-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!kill -9 8885"],"metadata":{"id":"qcFmI5raCnqO"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t8NrVs17QmtK"},"outputs":[],"source":["import logging\n","import datasets\n","from datasets import load_dataset, load_metric\n","from torch.utils.data import DataLoader\n","from tqdm.auto import tqdm, trange\n","import math\n","\n","import transformers\n","from accelerate import Accelerator\n","from transformers import (\n","    AdamW,\n","    AutoConfig,\n","    default_data_collator,\n","    get_scheduler\n",")\n","\n","train_batch_size = 4      # 設定 training batch size \n","eval_batch_size = 4      # 設定 eval batch size\n","num_train_epochs = 1      # 設定 epoch "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wFsfSI_7CrvV"},"outputs":[],"source":["data_collator = default_data_collator\n","train_dataloader = DataLoader(train_dataset, shuffle=True, collate_fn=data_collator, batch_size=train_batch_size)\n","eval_dataloader = DataLoader(eval_dataset, collate_fn=data_collator, batch_size=eval_batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1685259646648,"user":{"displayName":"許家紳","userId":"14766431505425888321"},"user_tz":-480},"id":"nD26g1wet9j9","outputId":"02f59a5e-8db4-4293-9956-4fae6a397b45"},"outputs":[{"output_type":"stream","name":"stdout","text":["max_train_steps 2807\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["learning_rate=3e-5          # 設定 learning_rate\n","gradient_accumulation_steps = 1   # 設定 幾步後進行反向傳播\n","\n","no_decay = [\"bias\", \"LayerNorm.weight\"]\n","optimizer_grouped_parameters = [\n","    {\n","        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","        \"weight_decay\": 0.0,\n","    },                                \n","    {\n","        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n","        \"weight_decay\": 0.0,\n","    },\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n","\n","# Scheduler and math around the number of training steps.\n","num_update_steps_per_epoch = math.ceil(len(train_dataloader) / gradient_accumulation_steps)\n","max_train_steps = num_train_epochs * num_update_steps_per_epoch\n","print('max_train_steps', max_train_steps)\n","\n","# scheduler\n","lr_scheduler = get_scheduler(\n","    name=\"linear\",\n","    optimizer=optimizer,\n","    num_warmup_steps=0,\n","    num_training_steps=max_train_steps,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lHOQDEHQC641","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685259653023,"user_tz":-480,"elapsed":6397,"user":{"displayName":"許家紳","userId":"14766431505425888321"}},"outputId":"ff9768c7-b0af-4c37-88c9-340ffcac1c7a"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-29-570f2d83a7b4>:10: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  metric = load_metric(\"accuracy\")\n"]}],"source":["\n","# Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n","accelerator = Accelerator()\n","\n","# Prepare everything with our `accelerator`.\n","model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n","    model, optimizer, train_dataloader, eval_dataloader\n",")\n","\n","eval_dataloader\n","metric = load_metric(\"accuracy\")"]},{"cell_type":"markdown","metadata":{"id":"rXx8f72fDLtr"},"source":["真正開始訓練"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b274ed843b2a439ab48b018ff1659caa","1c0dce42276c4b45b225413678d0c93d","d3250edfb2ac49ebb0925c74bbb97e65","ba9659545ca242e7888d60dbe4a2591c","0b91a15955374d239b84b65f1737dbb6","8f542faf022a464498f8e059c10217a1","8c80768d8af845be82ce7131b79040f7","f405de9707ef47fc9ebe0fca0300105d","b6509b43fb4e4c7abc80e478310473f1","9e6a78e41163411ba5bc9a3217c73570","b476f9d83aeb4a008f7753900c4ce516","3c1c33cd9a3e42cba8ae836047718f1d","a093481a3c2a4934bce86f25b22ed2be","fad69ad0fff44e0ea991867e29bf5e01","367bf00825c5455da9711fcb25a9fb7a","e39861937f4f45af82741100ad2df643","e954431d36ae4191a70d9e396e87d861","9effce9bfe4e4883bb95d4a64a1d5f0c","c30e1a3c431f46c3958a2e52682e8a0e","322be5f7fc2b4887a758d00f6f8f6cf3","5ec9ac8235b04d1e8b7d4a1fdd4d0fc8","2e7f61505cdc4e44a687d6a11f7aedb6"]},"id":"xnJyIO-vDJuY","outputId":"607f9792-8fc6-4244-de99-010014e7c2f3","executionInfo":{"status":"error","timestamp":1685259657606,"user_tz":-480,"elapsed":4590,"user":{"displayName":"許家紳","userId":"14766431505425888321"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b274ed843b2a439ab48b018ff1659caa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Iteration:   0%|          | 0/2807 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c1c33cd9a3e42cba8ae836047718f1d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'input_ids': tensor([[   259,  24636,  24696,  ...,      0,      0,      0],\n","        [   259, 108517, 108517,  ...,      0,      0,      0]],\n","       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'labels': tensor([1, 1], device='cuda:0')}\n","tensor([[   259,  24636,  24696,  ...,      0,      0,      0],\n","        [   259, 108517, 108517,  ...,      0,      0,      0]],\n","       device='cuda:0')\n","tensor([  259, 24636, 24696,  ...,     0,     0,     0], device='cuda:0')\n","tensor([   259, 108517, 108517,  ...,      0,      0,      0], device='cuda:0')\n","tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n","tensor([1, 1, 1,  ..., 0, 0, 0], device='cuda:0')\n","tensor([1, 1, 1,  ..., 0, 0, 0], device='cuda:0')\n","tensor([1, 1], device='cuda:0')\n","tensor(1, device='cuda:0')\n","tensor(1, device='cuda:0')\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92m<cell line: 25>\u001b[0m:\u001b[94m34\u001b[0m                                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/models/mt5/\u001b[0m\u001b[1;33mmodeling_mt5.py\u001b[0m:\u001b[94m1748\u001b[0m in \u001b[92mforward\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1745 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mdecoder_attention_mask = decoder_attention_mask.to(\u001b[96mself\u001b[0m.decoder.first_de  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1746 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1747 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Decode\u001b[0m                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1748 \u001b[2m│   │   \u001b[0mdecoder_outputs = \u001b[96mself\u001b[0m.decoder(                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1749 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids=decoder_input_ids,                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1750 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=decoder_attention_mask,                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1751 \u001b[0m\u001b[2m│   │   │   \u001b[0minputs_embeds=decoder_inputs_embeds,                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/models/mt5/\u001b[0m\u001b[1;33mmodeling_mt5.py\u001b[0m:\u001b[94m958\u001b[0m in \u001b[92mforward\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 955 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m.embed_tokens \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mYou have to initialize the model with\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 956 \u001b[0m\u001b[2m│   │   │   \u001b[0minputs_embeds = \u001b[96mself\u001b[0m.embed_tokens(input_ids)                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 957 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 958 \u001b[2m│   │   \u001b[0mbatch_size, seq_length = input_shape                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 959 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 960 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# required mask seq length can be calculated via length of past\u001b[0m                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 961 \u001b[0m\u001b[2m│   │   \u001b[0mmask_seq_length = past_key_values[\u001b[94m0\u001b[0m][\u001b[94m0\u001b[0m].shape[\u001b[94m2\u001b[0m] + seq_length \u001b[94mif\u001b[0m past_key_values  \u001b[31m│\u001b[0m\n","\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n","\u001b[1;91mValueError: \u001b[0mnot enough values to unpack \u001b[1m(\u001b[0mexpected \u001b[1;36m2\u001b[0m, got \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 25&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">34</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/models/mt5/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_mt5.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1748</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1745 │   │   │   │   </span>decoder_attention_mask = decoder_attention_mask.to(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.decoder.first_de  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1746 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1747 │   │   # Decode</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1748 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>decoder_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.decoder(                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1749 │   │   │   </span>input_ids=decoder_input_ids,                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1750 │   │   │   </span>attention_mask=decoder_attention_mask,                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1751 │   │   │   </span>inputs_embeds=decoder_inputs_embeds,                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/models/mt5/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_mt5.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">958</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 955 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embed_tokens <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"You have to initialize the model with</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 956 │   │   │   </span>inputs_embeds = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embed_tokens(input_ids)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 957 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 958 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>batch_size, seq_length = input_shape                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 959 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 960 │   │   # required mask seq length can be calculated via length of past</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 961 │   │   </span>mask_seq_length = past_key_values[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>][<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>].shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>] + seq_length <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> past_key_values  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>not enough values to unpack <span style=\"font-weight: bold\">(</span>expected <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, got <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n","</pre>\n"]},"metadata":{}}],"source":["logger = logging.getLogger(__name__)\n","logging.basicConfig(\n","    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n","    datefmt=\"%m/%d/%Y %H:%M:%S\",\n","    level=logging.INFO,\n",")\n","logger.info(accelerator.state)\n","output_dir = '/content/drive2/Shareddrives'  # your folder\n","\n","\n","total_batch_size = train_batch_size * accelerator.num_processes * gradient_accumulation_steps\n","\n","logger.info(\"***** Running training *****\")\n","logger.info(f\"  Num examples = {len(train_dataset)}\")\n","logger.info(f\"  Num Epochs = {num_train_epochs}\")\n","logger.info(f\"  Instantaneous batch size per device = {train_batch_size}\")\n","logger.info(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n","logger.info(f\"  Gradient Accumulation steps = {gradient_accumulation_steps}\")\n","logger.info(f\"  Total optimization steps = {max_train_steps}\")\n","\n","\n","completed_steps = 0\n","best_epoch = {\"epoch\": 0, \"acc\": 0 }\n","\n","for epoch in trange(num_train_epochs, desc=\"Epoch\"):#trange是print進度條的方式\n","\n","  model.train()\n","  for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n","    print(batch)\n","    for i in batch:\n","        print(batch[i])\n","        for j in batch[i]:\n","            print(j)\n","    outputs = model(**batch)\n","    print(outputs)\n","    #loss = outputs\n","    loss = outputs.loss\n","    #loss = loss / gradient_accumulation_steps\n","    accelerator.backward(loss)\n","    #if step % gradient_accumulation_steps == 0 or step == len(train_dataloader) - 1: 把if刪掉了\n","    optimizer.step()\n","    lr_scheduler.step()\n","    optimizer.zero_grad()\n","    completed_steps += 1\n","\n","    if step % 50 == 0:\n","      print({'epoch': epoch, 'step': step, 'loss': loss.item()})\n","\n","    if completed_steps >= max_train_steps:\n","      break\n","      \n","  logger.info(\"***** Running eval *****\")\n","  model.eval()\n","  for step, batch in enumerate(tqdm(eval_dataloader, desc=\"eval Iteration\")):\n","    outputs = model(**batch)\n","    predictions = outputs.logits.argmax(dim=-1)\n","    metric.add_batch(\n","        predictions=accelerator.gather(predictions),\n","        references=accelerator.gather(batch[\"labels\"]),\n","    )\n","\n","  eval_metric = metric.compute()\n","  logger.info(f\"epoch {epoch}: {eval_metric}\")\n","  if eval_metric['accuracy'] > best_epoch['acc']:\n","    best_epoch.update({\"epoch\": epoch, \"acc\": eval_metric['accuracy']})\n","\n","  if output_dir is not None:\n","    accelerator.wait_for_everyone()\n","    unwrapped_model = accelerator.unwrap_model(model)\n","    unwrapped_model.save_pretrained(output_dir + '/' + 'epoch_' + str(epoch), save_function=accelerator.save)"]},{"cell_type":"markdown","metadata":{"id":"n8u6P-Ixc21H"},"source":["## 最好的某次訓練成果"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qy7L_tQWOWje"},"outputs":[],"source":["print(best_epoch)"]},{"cell_type":"markdown","metadata":{"id":"y-gz6upcExbk"},"source":["# 訓練成果驗證"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4W2sRVsEOewE"},"outputs":[],"source":["from transformers import T5TokenizerFast, MT5Config, MT5ModelForSeq2SeqLM, default_data_collator\n","from torch.utils.data import DataLoader\n","from accelerate import Accelerator\n","from tqdm.auto import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-OCCA1KfBssu"},"outputs":[],"source":["#cd drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8vr2rQRBPKNE"},"outputs":[],"source":["#ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2R1qqANWPfwb"},"outputs":[],"source":["config = MT5Config.from_pretrained(\"./drive2/Shareddrives/epoch_2/config.json\") \n","model = MT5ModelForSeq2SeqLM.from_pretrained(\"./drive2/Shareddrives/epoch_2/pytorch_model.bin\", config = config).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"My-oSopAUBHY"},"outputs":[],"source":["def mrpc_model(model, sen1, sen2):\n","  input_encodings = tokenizer([sen1], [sen2], padding='max_length', truncation=True)\n","  input_dataset = Dataset(input_encodings)\n","  #print(input_encodings)\n","  #print(input_dataset[0])\n","  data_collator = default_data_collator\n","  input_dataloader = DataLoader(input_dataset, collate_fn=data_collator, batch_size=1)  \n","\n","  accelerator = Accelerator()\n","  model, input_dataloader = accelerator.prepare(model, input_dataloader)\n","\n","  for batch in input_dataloader:\n","    outputs = model(**batch)\n","    predicted = outputs.logits.argmax(dim=-1)\n","  return predicted"]},{"cell_type":"markdown","metadata":{"id":"yJiTwTBLr3OU"},"source":["### 可以拿來玩的地方"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y7oT34O6UG3I"},"outputs":[],"source":["sen1=\"lisa goes to school everyday\"\n","sen2=\"lisa everyday goes to school\"\n","#sen1=\"lisa is a singer\"\n","#sen2=\"lisa is not a singer\"\n","\n","predict = mrpc_model(model, sen1, sen2)\n","print(\"sentence= : \", sen1)\n","print(\"sentence= : \", sen2)\n","\n","print(\"predict_label : \", predict.item())\n","if predict.item():\n","  print(\"有關聯\")\n","else:\n","  print(\"沒關聯\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y9KMvZeTtUIQ"},"outputs":[],"source":["cnt=0\n","errorcnt=0\n","answer=[]\n","for i in range(len(testlabel)):\n","    if testlabel[i]==0 or testlabel[i]==1:\n","        cnt+=1\n","        sen1=test_sen1[i]\n","        sen2=test_sen2[i]\n","        predict=mrpc_model(model,sen1,sen2)\n","        #print(\"sentence= : \", sen1)\n","        #print(\"sentence= : \", sen2)\n","        answer.append(predict.item())\n","        #print(\"predict_label : \", predict.item())\n","        if predict.item()!=testlabel[i]:\n","            errorcnt+=1\n","        \n","print(cnt)\n","print(errorcnt)\n","print(1-(errorcnt/cnt))"]},{"cell_type":"markdown","metadata":{"id":"Vl2etcsuUGVh"},"source":["結果存進google drive"]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","print(\"no support=0. support=1\")\n","print(classification_report(testlabel,answer))"],"metadata":{"id":"PUsvmvhIK_wH"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fHekoG55sgj8"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ljLN4xHwuIvd"},"outputs":[],"source":["cd gdrive/MyDrive/Colab Notebooks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CI3Alzs7WF9O"},"outputs":[],"source":["\n","#torch.save(model,\"./test_model2\")\n","torch.save(model,\"./test_model2.bin\")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1RoU8b1P27Bz9tNpOCCGnQq3UJq6W46S9","timestamp":1683968512602},{"file_id":"1RoOmcO0aVc8xkYM0j8kSdclqwaU9qCcS","timestamp":1683360270625}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b274ed843b2a439ab48b018ff1659caa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1c0dce42276c4b45b225413678d0c93d","IPY_MODEL_d3250edfb2ac49ebb0925c74bbb97e65","IPY_MODEL_ba9659545ca242e7888d60dbe4a2591c"],"layout":"IPY_MODEL_0b91a15955374d239b84b65f1737dbb6"}},"1c0dce42276c4b45b225413678d0c93d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f542faf022a464498f8e059c10217a1","placeholder":"​","style":"IPY_MODEL_8c80768d8af845be82ce7131b79040f7","value":"Epoch:   0%"}},"d3250edfb2ac49ebb0925c74bbb97e65":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_f405de9707ef47fc9ebe0fca0300105d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b6509b43fb4e4c7abc80e478310473f1","value":0}},"ba9659545ca242e7888d60dbe4a2591c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e6a78e41163411ba5bc9a3217c73570","placeholder":"​","style":"IPY_MODEL_b476f9d83aeb4a008f7753900c4ce516","value":" 0/1 [00:01&lt;?, ?it/s]"}},"0b91a15955374d239b84b65f1737dbb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f542faf022a464498f8e059c10217a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c80768d8af845be82ce7131b79040f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f405de9707ef47fc9ebe0fca0300105d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6509b43fb4e4c7abc80e478310473f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e6a78e41163411ba5bc9a3217c73570":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b476f9d83aeb4a008f7753900c4ce516":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c1c33cd9a3e42cba8ae836047718f1d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a093481a3c2a4934bce86f25b22ed2be","IPY_MODEL_fad69ad0fff44e0ea991867e29bf5e01","IPY_MODEL_367bf00825c5455da9711fcb25a9fb7a"],"layout":"IPY_MODEL_e39861937f4f45af82741100ad2df643"}},"a093481a3c2a4934bce86f25b22ed2be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e954431d36ae4191a70d9e396e87d861","placeholder":"​","style":"IPY_MODEL_9effce9bfe4e4883bb95d4a64a1d5f0c","value":"Iteration:   0%"}},"fad69ad0fff44e0ea991867e29bf5e01":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_c30e1a3c431f46c3958a2e52682e8a0e","max":2807,"min":0,"orientation":"horizontal","style":"IPY_MODEL_322be5f7fc2b4887a758d00f6f8f6cf3","value":0}},"367bf00825c5455da9711fcb25a9fb7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ec9ac8235b04d1e8b7d4a1fdd4d0fc8","placeholder":"​","style":"IPY_MODEL_2e7f61505cdc4e44a687d6a11f7aedb6","value":" 0/2807 [00:01&lt;?, ?it/s]"}},"e39861937f4f45af82741100ad2df643":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e954431d36ae4191a70d9e396e87d861":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9effce9bfe4e4883bb95d4a64a1d5f0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c30e1a3c431f46c3958a2e52682e8a0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"322be5f7fc2b4887a758d00f6f8f6cf3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5ec9ac8235b04d1e8b7d4a1fdd4d0fc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e7f61505cdc4e44a687d6a11f7aedb6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}